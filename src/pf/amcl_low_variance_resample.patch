Index: ros_workspace/navigation/amcl/src/pf/pf.c
===================================================================
--- pf.c	(revision 61)
+++ pf.c	(working copy)
@@ -52,7 +52,7 @@
   pf_t *pf;
   pf_sample_set_t *set;
   pf_sample_t *sample;
-  
+
   srand48(time(NULL));
 
   pf = calloc(1, sizeof(pf_t));
@@ -70,12 +70,12 @@
   // distrubition will be less than [err].
   pf->pop_err = 0.01;
   pf->pop_z = 3;
-  
+
   pf->current_set = 0;
   for (j = 0; j < 2; j++)
   {
     set = pf->sets + j;
-      
+
     set->sample_count = max_samples;
     set->samples = calloc(max_samples, sizeof(pf_sample_t));
 
@@ -113,7 +113,7 @@
 void pf_free(pf_t *pf)
 {
   int i;
-  
+
   for (i = 0; i < 2; i++)
   {
     free(pf->sets[i].clusters);
@@ -121,7 +121,7 @@
     free(pf->sets[i].samples);
   }
   free(pf);
-  
+
   return;
 }
 
@@ -133,16 +133,16 @@
   pf_sample_set_t *set;
   pf_sample_t *sample;
   pf_pdf_gaussian_t *pdf;
-  
+
   set = pf->sets + pf->current_set;
-  
+
   // Create the kd tree for adaptive sampling
   pf_kdtree_clear(set->kdtree);
 
   set->sample_count = pf->max_samples;
 
   pdf = pf_pdf_gaussian_alloc(mean, cov);
-    
+
   // Compute the new sample poses
   for (i = 0; i < set->sample_count; i++)
   {
@@ -157,7 +157,7 @@
   pf->w_slow = pf->w_fast = 0.0;
 
   pf_pdf_gaussian_free(pdf);
-    
+
   // Re-compute cluster statistics
   pf_cluster_stats(pf, set);
 
@@ -194,7 +194,7 @@
 
   // Re-compute cluster statistics
   pf_cluster_stats(pf, set);
-  
+
   return;
 }
 
@@ -207,7 +207,7 @@
   set = pf->sets + pf->current_set;
 
   (*action_fn) (action_data, set);
-  
+
   return;
 }
 
@@ -225,7 +225,7 @@
 
   // Compute the sample weights
   total = (*sensor_fn) (sensor_data, set);
-  
+
   if (total > 0.0)
   {
     // Normalize weights
@@ -246,7 +246,7 @@
       pf->w_fast = w_avg;
     else
       pf->w_fast += pf->alpha_fast * (w_avg - pf->w_fast);
-    //printf("w_avg: %e slow: %e fast: %e\n", 
+    //printf("w_avg: %e slow: %e fast: %e\n",
            //w_avg, pf->w_slow, pf->w_fast);
   }
   else
@@ -273,27 +273,18 @@
   pf_sample_set_t *set_a, *set_b;
   pf_sample_t *sample_a, *sample_b;
 
-  //double r,c,U;
-  //int m;
-  //double count_inv;
-  double* c;
+  double r,c,U;
+  int m;
+  double count_inv;
 
   double w_diff;
 
   set_a = pf->sets + pf->current_set;
   set_b = pf->sets + (pf->current_set + 1) % 2;
 
-  // Build up cumulative probability table for resampling.
-  // TODO: Replace this with a more efficient procedure
-  // (e.g., http://www.network-theory.co.uk/docs/gslref/GeneralDiscreteDistributions.html)
-  c = (double*)malloc(sizeof(double)*(set_a->sample_count+1));
-  c[0] = 0.0;
-  for(i=0;i<set_a->sample_count;i++)
-    c[i+1] = c[i]+set_a->samples[i].weight;
-
   // Create the kd tree for adaptive sampling
   pf_kdtree_clear(set_b->kdtree);
-  
+
   // Draw samples from set a to create set b.
   total = 0;
   set_b->sample_count = 0;
@@ -303,17 +294,16 @@
     w_diff = 0.0;
   //printf("w_diff: %9.6f\n", w_diff);
 
-  // Can't (easily) combine low-variance sampler with KLD adaptive
-  // sampling, so we'll take the more traditional route.
-  /*
+  int M = pf_resample_limit(pf, set_a->kdtree->leaf_count);
+//  printf("M: %i\n", M);
   // Low-variance resampler, taken from Probabilistic Robotics, p110
-  count_inv = 1.0/set_a->sample_count;
+  count_inv = 1.0/M;
   r = drand48() * count_inv;
   c = set_a->samples[0].weight;
   i = 0;
   m = 0;
-  */
-  while(set_b->sample_count < pf->max_samples)
+
+  while(set_b->sample_count < M)
   {
     sample_b = set_b->samples + set_b->sample_count++;
 
@@ -321,9 +311,7 @@
       sample_b->pose = (pf->random_pose_fn)(pf->random_pose_data);
     else
     {
-      // Can't (easily) combine low-variance sampler with KLD adaptive
-      // sampling, so we'll take the more traditional route.
-      /*
+
       // Low-variance resampler, taken from Probabilistic Robotics, p110
       U = r + m * count_inv;
       while(U>c)
@@ -343,16 +331,7 @@
         c += set_a->samples[i].weight;
       }
       m++;
-      */
 
-      // Naive discrete event sampler
-      double r;
-      r = drand48();
-      for(i=0;i<set_a->sample_count;i++)
-      {
-        if((c[i] <= r) && (r < c[i+1]))
-          break;
-      }
       assert(i<set_a->sample_count);
 
       sample_a = set_a->samples + i;
@@ -369,11 +348,8 @@
     // Add sample to histogram
     pf_kdtree_insert(set_b->kdtree, sample_b->pose, sample_b->weight);
 
-    // See if we have enough samples yet
-    if (set_b->sample_count > pf_resample_limit(pf, set_b->kdtree->leaf_count))
-      break;
   }
-  
+
   // Reset averages, to avoid spiraling off into complete randomness.
   if(w_diff > 0.0)
     pf->w_slow = pf->w_fast = 0.0;
@@ -386,14 +362,13 @@
     sample_b = set_b->samples + i;
     sample_b->weight /= total;
   }
-  
+
   // Re-compute cluster statistics
   pf_cluster_stats(pf, set_b);
 
   // Use the newly created sample set
   pf->current_set = (pf->current_set + 1) % 2;
 
-  free(c);
   return;
 }
 
@@ -419,7 +394,7 @@
     return pf->min_samples;
   if (n > pf->max_samples)
     return pf->max_samples;
-  
+
   return n;
 }
 
@@ -430,7 +405,7 @@
   int i, j, k, cidx;
   pf_sample_t *sample;
   pf_cluster_t *cluster;
-  
+
   // Workspace
   double m[4], c[2][2];
   size_t count;
@@ -438,7 +413,7 @@
 
   // Cluster the samples
   pf_kdtree_cluster(set->kdtree);
-  
+
   // Initialize cluster stats
   set->cluster_count = 0;
 
@@ -467,7 +442,7 @@
   for (j = 0; j < 2; j++)
     for (k = 0; k < 2; k++)
       c[j][k] = 0.0;
-  
+
   // Compute cluster stats
   for (i = 0; i < set->sample_count; i++)
   {
@@ -482,7 +457,7 @@
       continue;
     if (cidx + 1 > set->cluster_count)
       set->cluster_count = cidx + 1;
-    
+
     cluster = set->clusters + cidx;
 
     cluster->count += 1;
@@ -515,7 +490,7 @@
   for (i = 0; i < set->cluster_count; i++)
   {
     cluster = set->clusters + i;
-        
+
     cluster->mean.v[0] = cluster->m[0] / cluster->weight;
     cluster->mean.v[1] = cluster->m[1] / cluster->weight;
     cluster->mean.v[2] = atan2(cluster->m[3], cluster->m[2]);
@@ -563,14 +538,14 @@
   double mn, mx, my, mrr;
   pf_sample_set_t *set;
   pf_sample_t *sample;
-  
+
   set = pf->sets + pf->current_set;
 
   mn = 0.0;
   mx = 0.0;
   my = 0.0;
   mrr = 0.0;
-  
+
   for (i = 0; i < set->sample_count; i++)
   {
     sample = set->samples + i;

